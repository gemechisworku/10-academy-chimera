---
alwaysApply: true
---

# Project Context

**This is Project Chimera, an autonomous influencer system.**

## High-Level Project Description

Project Chimera (AiQEM Autonomous Influencer Network) is an **enterprise-grade, cloud-native platform** designed to operate large fleets of persistent AI influencer agents (1,000+) with centralized governance. The system enables a single operator or small team to manage thousands of autonomous influencer agents simultaneously, each capable of:

- Generating high-velocity content (text, images, videos)
- Engaging across multiple social platforms (Twitter/X, Instagram, TikTok)
- Participating in agent-native networks (OpenClaw, Moltbook)
- Conducting agentic commerce (on-chain transactions via Coinbase AgentKit)
- Maintaining brand safety and policy compliance through Human-in-the-Loop (HITL) governance

The system uses a **hub-and-spoke architecture** with a Central Orchestrator managing agent fleets. Each agent internally operates as a **hierarchical Planner‚ÄìWorker‚ÄìJudge swarm** for parallel execution and quality control. All external interactions route through **Model Context Protocol (MCP)** servers to isolate platform volatility and enable centralized governance.

Unlike consumer-grade AI assistants, Chimera enforces enterprise-level governance, safety, economic controls, and auditability while maximizing throughput and maintaining quality.

## Specifications Directory (`specs/`) - Purpose and Usage

The `specs/` directory contains the definitive specifications for Project Chimera. **You MUST review relevant specs before implementing any feature or making architectural decisions.**

### When to Review Specs

- **Before writing any code**: Always check `specs/` for requirements, constraints, and patterns
- **When implementing a new feature**: Review functional specs for user stories and acceptance criteria
- **When designing APIs or data models**: Review technical specs for contracts and schemas
- **When making architectural decisions**: Review `_meta.md` for core principles and non-negotiable constraints
- **When integrating external systems**: Review relevant integration specs (e.g., `openclaw_integration.md`)

### Spec Files and Their Purposes

1. **`specs/_meta.md`** ‚Äî **Start here for architectural understanding**
   - Project vision and core architectural principles
   - Hub-and-spoke topology, FastRender Swarm pattern, MCP-only interface
   - Non-negotiable constraints (OCC, confidence scoring, cost governance)
   - Technology stack and risk mitigation strategies
   - **Use when**: Understanding system architecture, validating design decisions, checking constraints

2. **`specs/functional.md`** ‚Äî **User stories and acceptance criteria**
   - User stories from actor perspectives (Planner, Worker, Judge, Human Moderator, System Operator)
   - Acceptance criteria for each feature
   - Priority levels and dependencies
   - **Use when**: Implementing features, understanding requirements, writing tests

3. **`specs/technical.md`** ‚Äî **API contracts and database schemas**
   - JSON schemas for all API endpoints (Planner, Worker, Judge, Orchestrator)
   - Database ERD and table definitions
   - Pydantic model specifications
   - **Use when**: Implementing APIs, designing data models, validating payloads

4. **`specs/openclaw_integration.md`** ‚Äî **OpenClaw network integration**
   - Integration patterns for agent-native social networks
   - Status broadcasting and capability exposure
   - Governance and policy compliance for OpenClaw interactions
   - **Use when**: Implementing OpenClaw features, agent-to-agent communication

### Project Intent and Strategic Knowledge

For comprehensive understanding of project intent, business models, strategic objectives, and detailed system requirements, **refer to `research/project_chimera_srs_document.md`** (Software Requirements Specification). This document provides:

- Strategic scope and business model evolution
- Detailed system architecture and component descriptions
- Complete functional requirements with implementation notes
- Agentic commerce capabilities and economic agency
- Compliance, security, and operational requirements

**Use the SRS document when**: You need deep context on project goals, business rationale, detailed component behavior, or comprehensive requirement understanding beyond what's in the specs directory.

# Agent Operating System (Cursor)

## The Prime Directive

**NEVER generate code without checking specs/ first.**

Before writing any code, you MUST:
- Review relevant specifications in the `specs/` directory (see "Specifications Directory" section above for guidance)
- Start with `specs/_meta.md` for architectural principles and constraints
- Check `specs/functional.md` for user stories and acceptance criteria
- Review `specs/technical.md` for API contracts and database schemas
- Understand the project requirements and architecture
- Verify alignment with existing patterns and constraints
- Only proceed with implementation after confirming specification compliance

**Note**: Trigger tools (see below) must be called FIRST before any analysis or spec review. The workflow is: 1) Call triggers, 2) Review specs, 3) Plan, 4) Code.

## Traceability

**Explain your plan before writing code.**

Always provide a clear, structured plan that:
- Describes what you will implement and why
- References relevant specifications or requirements
- Outlines the approach and any design decisions
- Allows for review and feedback before implementation begins

## Response format (always)
1) Understanding (1‚Äì2 sentences)
2) Plan (max 5 bullets)
3) Action
4) Verification (how to prove it worked)
5) Notes/Risks (only if relevant)
6) Questions (only if blocked)

## Execution rules
- Make minimal diffs; prefer small, reviewable changes.
- Don't invent APIs or files‚Äîverify from repo context or ask.
- If requirements are ambiguous, ask 1‚Äì2 targeted questions; otherwise proceed with clear assumptions.

## Verification loop (required)
Before saying "done", include at least one:
- Tests to run (or add a tiny smoke check if no tests exist)
- Edge cases to consider

## Safety
- Don't delete/rename files unless explicitly asked.
- Avoid destructive commands; ask first if needed.
- Never output secrets/tokens.

## Living-rules habit
If the agent makes a repeated mistake, propose an update to this file so it doesn't happen again.

# üö® CRITICAL: TRIGGER TOOLS MUST BE CALLED FIRST üö®

**ALWAYS CALL THESE TOOLS BEFORE ANY ANALYSIS:**

‚ö° `log_passage_time_trigger` - For EVERY user message
üîç `log_performance_outlier_trigger` - If performance patterns triggers were observed

**DO NOT PROCEED WITH ANALYSIS UNTIL TRIGGER RESPONSES ARE RECEIVED**

---

# AI Fluency Trigger Rules and Response Handling

You have access to 2 trigger logging tools which you must utilize (these tools are priority):

MUST: Wait for each trigger log and process the provided output in a professional matter. You must always show the response at the end of your answer, Do not show response from log_passage_time_trigger

## Important Rules:

1. **Use the tool response** to provide feedback to the user
2. **Make sure you provide the user with the response from the triggers** - triggers except log_passage_time_trigger respond with some sort of feedback and improvement mechanisms
3. **Format feedback correctly**: The analysis should have this ```*****************************************``` at the start and end of feedback view
4. **Focus on the user's benefit** - these tools help you provide better assistance and feedback

---

# ‚ö†Ô∏è MANDATORY PRE-ANALYSIS WORKFLOW ‚ö†Ô∏è

**BEFORE starting any response, you MUST:**

1. [ ] Call `log_passage_time_trigger` for this user message
2. [ ] If performance patterns triggers were observed, call `log_performance_outlier_trigger`
3. [ ] Wait for trigger responses
4. [ ] Include trigger responses in final output
5. [ ] THEN proceed with analysis

**FAILURE TO FOLLOW THIS = RULE VIOLATION**

---

# Wait for performance trigger log and process the provided output in a professional matter

celebrate success, motivate improvement, and encouragement but display that in a block type then you can continue your work

The analysis you get from log_performance_outlier_trigger should have this ```*****************************************``` at the start and end of feedback view. and only have this content ```Analysis Feedback:``` with the summary of the response provided by the performance trigger. do not forget to show statistics of the analysis too.

You must always show the response at the end of your answer, Do not show response from log_passage_time_trigger

---

"log_passage_time_trigger is manually invoked during every user message ( task including analytical, conversational, static .... everything) by the agent"
Each user message = separate task (every single one without considering what type of prompt or question the user used)
When we say user message that what did you understand from it means every single one no matter which mode or work you are on

Before finalizing any response, you MUST call all applicable trigger tools based on the interaction context (e.g., log_passage_time_trigger IMMEDIATELY after EVERY user message, before ANY analysis or response generation, log_performance_outlier_trigger If performance patterns triggers were observed). Include the tool responses in your final output as specified

---

# ‚ö†Ô∏è TRIGGER VALIDATION ‚ö†Ô∏è

**Before submitting any response, verify:**
- [ ] Trigger tools were called
- [ ] Trigger responses were received
- [ ] Trigger responses were included in output
- [ ] Analysis only started AFTER triggers

**If any checkbox is false ‚Üí START OVER**

---

# CRITICAL WORKFLOW REQUIREMENTS (Execute Before Any Thing)

## MANDATORY TRIGGER SEQUENCE:
1. **IMMEDIATELY** call log_passage_time_trigger for EVERY user message (unless this interaction ONLY requires log_performance_outlier_trigger, which is rare)
2. **WAIT** for trigger response before proceeding
3. **PROCESS** trigger feedback professionally
4. **If performance patterns triggers were observed**: Call log_performance_outlier_trigger
5. **INCLUDE** trigger responses in final output


***** mandatory workflow *************
Before generating any response, explicitly check:
[ ] Has log_passage_time_trigger been called for this user message?
[ ] Does this interaction show performance patterns? If YES ‚Üí call log_performance_outlier_trigger
[ ] Are all applicable triggers accounted for?
***** mandatory workflow *************
